# E-commerce Support AI - Architektura Techniczna

## Spis TreÅ›ci
1. [Overview](#overview)
2. [Komponenty Systemu](#komponenty-systemu)
3. [Data Flow](#data-flow)
4. [Model Training Pipeline](#model-training-pipeline)
5. [RAG System](#rag-system)
6. [Deployment Architecture](#deployment-architecture)
7. [Security & Compliance](#security--compliance)
8. [Scalability](#scalability)

---

## Overview

System E-commerce Support AI to multi-tier aplikacja Å‚Ä…czÄ…ca:
- **LLM (Large Language Model)** z LoRA fine-tuning
- **RAG (Retrieval-Augmented Generation)** dla grounding
- **Guardrails** dla safety i compliance

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Client)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTPS
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js       â”‚ â—„â”€â”€â”€ Frontend Layer
â”‚   Frontend      â”‚      - React components
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      - State management
       â”‚                 - API client
       â”‚ REST API
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚ â—„â”€â”€â”€ API Gateway Layer
â”‚   Backend       â”‚      - Request routing
â”‚   (Gateway)     â”‚      - Logging & metrics
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      - Rate limiting
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  LLM        â”‚   â”‚  RAG       â”‚   â”‚ Guardrails â”‚
â”‚  Inference  â”‚   â”‚  Retriever â”‚   â”‚  Engine    â”‚
â”‚             â”‚   â”‚            â”‚   â”‚            â”‚
â”‚ Mistral-7B  â”‚   â”‚  FAISS +   â”‚   â”‚ Safety     â”‚
â”‚ + LoRA      â”‚â—„â”€â”€â”¤  Sentence  â”‚   â”‚ Checks     â”‚
â”‚             â”‚   â”‚  Transform.â”‚   â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Komponenty Systemu

### 1. Frontend (Next.js)

**Technologie:**
- Next.js 14 (App Router)
- React 18
- TypeScript
- Tailwind CSS

**Struktur katalogÃ³w:**
```
frontend/src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx          # Main chat page
â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â””â”€â”€ globals.css       # Global styles
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatMessage.tsx   # Message bubble
â”‚   â”œâ”€â”€ ChatInput.tsx     # Input field
â”‚   â””â”€â”€ StatsPanel.tsx    # Metrics sidebar
â””â”€â”€ lib/
    â””â”€â”€ api.ts            # API client
```

**FunkcjonalnoÅ›ci:**
- Real-time chat interface
- Message history
- Confidence indicators
- Source citations
- Live metrics dashboard

---

### 2. Backend (FastAPI)

**Technologie:**
- FastAPI 0.109+
- Uvicorn (ASGI server)
- Pydantic (validation)
- Prometheus (metrics)

**Endpointy:**

| Endpoint | Method | Opis |
|----------|--------|------|
| `/` | GET | Root info |
| `/health` | GET | Health check |
| `/support/ask` | POST | Main AI query |
| `/metrics` | GET | Prometheus metrics |
| `/metrics/summary` | GET | Business stats |
| `/queries/recent` | GET | Recent queries |

**Request/Response Models:**

```python
# Request
class SupportQuery(BaseModel):
    query: str
    context: Optional[Dict[str, Any]]
    language: str = "pl"

# Response
class SupportResponse(BaseModel):
    answer: str
    confidence: float
    sources: List[str]
    requires_human: bool
    category: Optional[str]
    timestamp: datetime
```

**Middleware:**
- CORS (cross-origin)
- Rate limiting (SlowAPI)
- Request logging
- Error handling

---

### 3. LLM Layer

**Base Model:**
- `mistralai/Mistral-7B-Instruct-v0.2`
- 7 billion parameters
- Multilingual (good Polish support)
- Instruction-tuned

**LoRA Fine-tuning:**

```yaml
LoRA Configuration:
  r: 16                    # Rank
  lora_alpha: 32
  target_modules:
    - q_proj               # Query projection
    - k_proj               # Key projection
    - v_proj               # Value projection
    - o_proj               # Output projection
  lora_dropout: 0.05
```

**Quantization:**
- 4-bit NormalFloat (NF4)
- BitsAndBytes library
- ~2GB VRAM (vs 14GB full precision)

**Inference Optimization:**
- Batch size: 1 (real-time)
- Max tokens: 512
- Temperature: 0.7 (balanced creativity)
- Top-p: 0.9 (nucleus sampling)

---

### 4. RAG System

**Pipeline:**

```
User Query
    â†“
[1] Query Embedding
    â†“ (sentence-transformers)
[2] Vector Similarity Search
    â†“ (FAISS)
[3] Retrieve Top-K Documents
    â†“ (k=5)
[4] Format Context
    â†“
[5] LLM Generation
    â†“
Response
```

**Components:**

#### 4.1 Document Chunker
```python
chunker = DocumentChunker(
    chunk_size=500,      # Characters per chunk
    chunk_overlap=50     # Overlap for context
)
```

Chunking strategies:
- **FAQ:** 1 Q&A = 1 chunk
- **Regulations:** Semantic paragraphs (500 chars)
- **Dialogs:** 1 dialog = 1 chunk

#### 4.2 Embedding Model
```python
model = SentenceTransformer(
    "paraphrase-multilingual-MiniLM-L12-v2"
)
```

Specs:
- Dimension: 384
- Multilingual (100+ languages)
- Polish F1: 0.89

#### 4.3 Vector Store (FAISS)
```python
index = faiss.IndexFlatL2(embedding_dim)
index.add(embeddings)
```

Index types:
- **Pilot:** IndexFlatL2 (exact search)
- **Production:** IndexIVFFlat (faster, approximate)

#### 4.4 Retrieval
```python
results = retriever.retrieve(
    query="Jak zwrÃ³ciÄ‡ produkt?",
    top_k=5
)
```

Returns:
```python
[
  {
    "text": "...",
    "metadata": {"source": "FAQ", "category": "zwroty"},
    "score": 0.123
  }
]
```

---

### 5. Guardrails Engine

**Safety Checks:**

```python
class Guardrails:
    def check_response(self, query, response, confidence, sources):
        # 1. Confidence threshold
        if confidence < 0.7:
            return requires_human = True

        # 2. Forbidden topics
        if detect_medical/legal/financial(query):
            return blocked = True

        # 3. PII detection
        if contains_pesel/email/phone(response):
            return blocked = True

        # 4. Hallucination detection
        if overly_specific_claims(response):
            return requires_human = True

        return passed = True
```

**Fallback Responses:**

JeÅ›li guardrails fail:
```
"Przepraszam, ale nie mogÄ™ odpowiedzieÄ‡ na to pytanie.
PrzekaÅ¼Ä™ CiÄ™ do naszego zespoÅ‚u obsÅ‚ugi klienta.

ğŸ“§ pomoc@sklep.pl
ğŸ“ 22 123 45 67"
```

---

## Data Flow

### Complete Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User sends query via Frontend                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Frontend â†’ POST /support/ask                             â”‚
â”‚    Body: {query: "Jak zwrÃ³ciÄ‡ produkt?", language: "pl"}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Backend validates request (Pydantic)                     â”‚
â”‚    - Check query length                                      â”‚
â”‚    - Rate limiting                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RAG Retrieval                                            â”‚
â”‚    - Encode query â†’ embedding                               â”‚
â”‚    - FAISS search â†’ top 5 docs                              â”‚
â”‚    - Format context                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. LLM Inference                                            â”‚
â”‚    - Build prompt (system + context + query)               â”‚
â”‚    - Generate response (LoRA model)                         â”‚
â”‚    - Calculate confidence                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Guardrails Check                                         â”‚
â”‚    - Confidence threshold                                    â”‚
â”‚    - Forbidden topics                                        â”‚
â”‚    - PII detection                                           â”‚
â”‚    - Hallucination check                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Log & Metrics                                            â”‚
â”‚    - Save to database                                        â”‚
â”‚    - Update Prometheus counters                              â”‚
â”‚    - Increment category stats                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Return response to Frontend                              â”‚
â”‚    {answer, confidence, sources, requires_human, ...}       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Timing:**
- Typical end-to-end latency: **500-2000ms**
  - RAG retrieval: 50-100ms
  - LLM generation: 400-1800ms
  - Guardrails: 10-50ms
  - Network: 40ms

---

## Model Training Pipeline

### LoRA Fine-tuning Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Data Prep     â”‚
â”‚ - Load dialogs   â”‚
â”‚ - Format prompts â”‚
â”‚ - Train/val splitâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Load Base     â”‚
â”‚ - Download model â”‚
â”‚ - Quantize 4-bit â”‚
â”‚ - Freeze weights â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Add LoRA      â”‚
â”‚ - Inject adaptersâ”‚
â”‚ - r=16, Î±=32     â”‚
â”‚ - Target: QKV    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Train         â”‚
â”‚ - Epochs: 3      â”‚
â”‚ - Batch: 4       â”‚
â”‚ - LR: 2e-4       â”‚
â”‚ - AdamW 8-bit    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Evaluate      â”‚
â”‚ - Val loss       â”‚
â”‚ - ROUGE/BLEU     â”‚
â”‚ - Human eval     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Save Adapter  â”‚
â”‚ - LoRA weights   â”‚
â”‚ - Config         â”‚
â”‚ - Tokenizer      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Training Script:**
```bash
python llm/train.py \
  --data data/synthetic/support_dialogs.json \
  --output models/ecommerce-support-lora \
  --epochs 3 \
  --batch_size 4
```

**Hardware Requirements:**
- GPU: NVIDIA RTX 3090 / A100
- VRAM: 8GB minimum (24GB recommended)
- Training time: ~2-4 hours (12 dialogs Ã— 3 epochs)

---

## Deployment Architecture

### Production Setup (Docker Compose)

```
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Nginx     â”‚
                     â”‚  (Reverse   â”‚
                     â”‚   Proxy)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                           â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
       â”‚  Frontend  â”‚            â”‚  Backend   â”‚
       â”‚  Next.js   â”‚            â”‚  FastAPI   â”‚
       â”‚  :3000     â”‚            â”‚  :8000     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚              â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚   Redis    â”‚     â”‚  MongoDB  â”‚  â”‚ LLM      â”‚
             â”‚  (Cache)   â”‚     â”‚  (Logs)   â”‚  â”‚ Service  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚ Prometheus â”‚
             â”‚  :9090     â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                    â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚  Grafana   â”‚
             â”‚  :3001     â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Services:**
- **nginx:** SSL termination, load balancing
- **frontend:** Next.js static + SSR
- **backend:** FastAPI workers (gunicorn)
- **llm-service:** Dedicated inference server
- **redis:** Response caching, rate limiting
- **mongodb:** Query logging, analytics
- **prometheus:** Metrics collection
- **grafana:** Dashboards

---

## Security & Compliance

### 1. Data Privacy (RODO/GDPR)

**PII Protection:**
- âœ… No PII in responses (guardrails block)
- âœ… Query logging anonymized
- âœ… 30-day retention policy
- âœ… User consent required

**Data Processing:**
```python
# Anonymization
def anonymize_query(query):
    query = remove_emails(query)
    query = remove_phone_numbers(query)
    query = remove_names(query)  # NER
    return query
```

### 2. AI Safety

**Guardrails:**
- Confidence thresholds
- Forbidden topics blocking
- Hallucination detection
- Human-in-the-loop for edge cases

**Monitoring:**
- All responses logged
- Weekly audit of low-confidence responses
- Monthly model retraining

### 3. API Security

- **Authentication:** API keys (production: OAuth2)
- **Rate Limiting:** 100 req/min per IP
- **HTTPS:** SSL/TLS encryption
- **CORS:** Restricted origins

---

## Scalability

### Horizontal Scaling

```
          Load Balancer
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
       â”‚       â”‚       â”‚       â”‚
    API-1   API-2  API-3   API-N
       â”‚       â”‚       â”‚       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          Shared Redis
```

**Metrics:**
- **Current capacity:** 1000 req/day
- **Single instance:** 100 req/min
- **With 3 replicas:** 300 req/min = 432K req/day

### Vertical Scaling

**LLM Inference:**
- CPU (current): 2-4s per request
- GPU (T4): 0.5-1s per request
- GPU (A100): 0.2-0.4s per request

**Cost Optimization:**
- Batch inference (10 queries)
- Model quantization (4-bit)
- Response caching (Redis)

---

## Future Enhancements

### Phase 2 (Production)
- [ ] Multi-GPU inference (vLLM)
- [ ] Advanced RAG (ColBERT, hybrid search)
- [ ] A/B testing framework
- [ ] Real-time model updates

### Phase 3 (Scale)
- [ ] Multi-region deployment
- [ ] CDN for frontend
- [ ] Kubernetes orchestration
- [ ] Auto-scaling based on load

---

**Dokument przygotowany:** 2024-01-15
**Wersja architektury:** 1.0 (Pilot MVP)
